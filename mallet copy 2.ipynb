{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57c307d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/vedant/.local/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in /home/vedant/.local/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (9.0.1)\n",
      "Requirement already satisfied: ipython in /home/vedant/.local/lib/python3.10/site-packages (8.37.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython) (2.11.2)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (4.15.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: stack_data in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (1.3.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/vedant/.local/lib/python3.10/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/vedant/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.5)\n",
      "Requirement already satisfied: wcwidth in /home/vedant/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/vedant/.local/lib/python3.10/site-packages (from stack_data->ipython) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/vedant/.local/lib/python3.10/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/vedant/.local/lib/python3.10/site-packages (from stack_data->ipython) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy Pillow ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ae83eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "# Core libraries for computer vision\n",
    "import cv2  # OpenCV - the main computer vision library\n",
    "import numpy as np  # Numerical operations on arrays/images\n",
    "\n",
    "# Libraries for display in Jupyter Notebook\n",
    "from PIL import Image, ImageDraw, ImageFont  # Python Imaging Library\n",
    "from IPython.display import display, clear_output\n",
    "import IPython.display\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83658c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(frame, frame_size=(500, 300), title=\"Image\"):\n",
    "    \n",
    "    # Check if image is normalized (float between 0-1)\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "    \n",
    "    # Handle grayscale images\n",
    "    if len(frame.shape) == 2:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Convert BGR (OpenCV format) to RGB (PIL format)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize the frame for display\n",
    "    frame = cv2.resize(frame, frame_size)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    img = Image.fromarray(frame)\n",
    "\n",
    "    display(img)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frame(video_path, time_sec=1.0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    print(f\"Video Info:\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    print(f\"   Total frames: {total_frames}\")\n",
    "    print(f\"   Duration: {duration:.2f} seconds\")\n",
    "    \n",
    "    # Set frame position\n",
    "    frame_index = int(time_sec * fps)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Failed to capture frame at {time_sec} seconds\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Frame captured at {time_sec} seconds\")\n",
    "    return frame\n",
    "\n",
    "def enhance_contrast(img):\n",
    "    \"\"\"Enhance contrast using histogram equalization.\"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        # For color images, equalize each channel\n",
    "        r, g, b = cv2.split(img)\n",
    "        r_eq = cv2.equalizeHist(r)\n",
    "        g_eq = cv2.equalizeHist(g)\n",
    "        b_eq = cv2.equalizeHist(b)\n",
    "        return cv2.merge((r_eq, g_eq, b_eq))\n",
    "    else:\n",
    "        return cv2.equalizeHist(img)\n",
    "\n",
    "def apply_clahe(img, clip_limit=2.0, tile_size=(8, 8)):\n",
    "    \"\"\"Apply CLAHE for adaptive contrast enhancement.\"\"\"\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "    l_enhanced = clahe.apply(l)\n",
    "    \n",
    "    # Merge back\n",
    "    lab_enhanced = cv2.merge((l_enhanced, a, b))\n",
    "    return cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "def enhance_contrast(img):\n",
    "    \"\"\"Enhance contrast using histogram equalization.\"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        # For color images, equalize each channel\n",
    "        r, g, b = cv2.split(img)\n",
    "        r_eq = cv2.equalizeHist(r)\n",
    "        g_eq = cv2.equalizeHist(g)\n",
    "        b_eq = cv2.equalizeHist(b)\n",
    "        return cv2.merge((r_eq, g_eq, b_eq))\n",
    "    else:\n",
    "        return cv2.equalizeHist(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0113ea",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c1c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(frame):\n",
    "    \n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    frame = histogram_equalization(frame)\n",
    "    # Convert to HSV\n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    bgr = frame\n",
    "\n",
    "    lab = cv2.medianBlur(lab, 3)    #small  odd kernel\n",
    "    bgr = cv2.medianBlur(bgr, 3)\n",
    "    \n",
    "    return lab,bgr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fdcd5",
   "metadata": {},
   "source": [
    "THRESHOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(img1, img2):\n",
    "    if img1 is not None:\n",
    "        \n",
    "        L, A, B = cv2.split(img1)\n",
    "        \n",
    "        A = cv2.medianBlur(A, 5)\n",
    "        \n",
    "        lower_orange = np.array([0, 80, 160])\n",
    "        upper_orange = np.array([120, 200, 255])\n",
    "        mask = cv2.inRange(img2, lower_orange, upper_orange)\n",
    "        \n",
    "        mask_A = cv2.inRange(A, 130, 170)  #130\n",
    "        mask_B = cv2.inRange(B, 130, 180)  #150\n",
    "        mask_L = cv2.inRange(L, 150, 255)\n",
    "        \n",
    "        combined = cv2.bitwise_and(mask_A, mask_B)\n",
    "        combinedv2 = cv2.bitwise_and(combined, mask_L)\n",
    "        combinedv3 = cv2.bitwise_and(combinedv2, mask)\n",
    "        \n",
    "\n",
    "        display_image(combinedv3, title=\"Binary Image\")\n",
    "        return combinedv3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286cbea5",
   "metadata": {},
   "source": [
    "REFINEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f14d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinement(gray):\n",
    "    if gray is None:\n",
    "        return None\n",
    "\n",
    "    _, binary = cv2.threshold( gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (6,6))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "\n",
    "    display_image(binary, title=\"\")\n",
    "    \n",
    "    return binary       \n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa434505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMallet_videos/IMG_9118.MOV\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change to your video path\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[1;32m      3\u001b[0m fps \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS)\n\u001b[1;32m      4\u001b[0m size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_WIDTH)), \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_HEIGHT)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = \"Mallet_videos/IMG_9118.MOV\"  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "time_Sec = 0\n",
    "while cap.isOpened():\n",
    "    \n",
    "    frame = capture_frame(video_path, time_Sec)\n",
    "    \n",
    "    frame = apply_clahe(frame)\n",
    "    \n",
    "    if frame is None:\n",
    "        print(f\"No frame at {time_Sec:.2f}s â€” skipping\")\n",
    "        time_Sec += 0.33\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (size[0]//2, size[1]//2))\n",
    "    if frame is not None:\n",
    "        display_image(frame)    \n",
    "        \n",
    "    prepros_lab, prepros_bgr = preprocess_image(frame)\n",
    "    thresh = thresholding(prepros_lab, prepros_bgr)\n",
    "    refine = refinement(thresh)\n",
    "    \n",
    "    cv2.imshow(\"original\", frame)\n",
    "    cv2.imshow(\"preprocess_image lab\", prepros_lab)\n",
    "    cv2.imshow(\"preprocess_image hsv\", prepros_bgr)\n",
    "    cv2.imshow(\"beforr refinement\", thresh)\n",
    "    cv2.imshow(\"final\", refine)\n",
    "    cv2.waitKey(1)\n",
    "    time_Sec += 0.33\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
